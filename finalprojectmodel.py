# -*- coding: utf-8 -*-
"""FinalProjectModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-sjTIVByJSI16HV81Hs57rFjhlNuJB3h

# Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sn
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline
from imutils.perspective import four_point_transform

from google.colab import files
import os

# Unzip images, ignore this cell if files are already in the workspace
!unzip /content/handwritten_data.zip

"""# Data Understanding """

#to load data
imagepaths = []

count_dict = {}
count = 0
# Go through all the files and subdirectories inside a folder and save path to images inside list
for root, dirs, files in os.walk("/content/handwritten_data", topdown=False): 
  count = count+1
  imgs = 0
  for name in files:
    
    #print(os.path.basename(name))
    path = os.path.join(root, name)
    if path.endswith("png"): # We want only the images
      imgs = imgs+1
      label_num = int(path.split("/")[3])
      count_dict["label_"+str(label_num)] = imgs
      imagepaths.append(path)

print("Total Images: ", len(imagepaths))
print(count_dict)

def plot_image(path):
  img = cv2.imread(path) # Reads the image into a numpy.array
  img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (RGB)
  print(img_cvt.shape) # Prints the shape of the image just to check
  plt.grid(False) # Without grid so we can see better
  
  plt.imshow(img_cvt) # Shows the image
  plt.xlabel("Width")
  plt.ylabel("Height")
  plt.title("Image " + path)

plot_image(imagepaths[10])

"""Display Data

"""

plt.figure(figsize=(50, 25))
plt.xlabel("labels")
plt.xticks( fontsize=18)
plt.bar(*zip(*count_dict.items()))

plt.show()

X = [] # Image data
y = [] # Labels

# Loops through imagepaths to load images and labels into arrays
for path in imagepaths:
  img = cv2.imread(path) # Reads image and returns np.array
  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (GRAY)

  (thresh, blackAndWhiteImage) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
  blur=((3,3),1)
  erode_=(5,5)
  dilate_=(3, 3)
  img_smooth =cv2.dilate(cv2.erode(cv2.GaussianBlur(blackAndWhiteImage/255, blur[0], blur[1]), np.ones(erode_)), np.ones(dilate_))*255

  X.append(img_smooth)
  
  # Processing label in image path
  category = path.split("/")[3]
  #print(path)
  label = int(category) # We need to convert 10_down to 00_down, or else it crashes
  y.append(label-1)
 
#plt.imshow(X[0],)

# Turn X and y into np.array to speed up train_test_split
X = np.array(X, dtype="uint8")
X = X.reshape(len(imagepaths), 50, 50, 1) # Needed to reshape so CNN knows it's different images
y = np.array(y)
y = y.reshape(len(y),1)


print("Images loaded: ", len(X))
print("Labels loaded: ", len(y))

print("Label No.",y[0], " path: ",imagepaths[0]) # Debugging

print(X.shape,y.shape)

#labels
num_classes = len(np.unique(y))
print(num_classes)

print(np.unique(y))

"""# Data Preprocessing

"""

# Sklearn
from sklearn.model_selection import train_test_split # Helps with organizing data for training
from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matrix

ts = 0.2 # Percentage of images that we want to use for testing. The rest is used for training.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=42)

print(X_train.shape,y_train.shape)

print(X_test.shape,y_test.shape)

"""# Model

"""

# Import of keras model and hidden layers for our convolutional network
from keras.models import Sequential
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers import Dense, Flatten,BatchNormalization, Dropout

from keras.utils import to_categorical

X_train = X_train/255
X_test = X_test/255

# Construction of model
model = Sequential()

model.add(Conv2D(32, 3,activation='relu',input_shape=(50,50,1))) 
model.add(MaxPooling2D((2, 2)))


model.add(Conv2D(64, 3, padding="same", activation='relu')) 
model.add(MaxPooling2D((2, 2)))


model.add(Conv2D(64, 3, padding="same",activation='relu'))
model.add(MaxPooling2D((2, 2)))


model.add(Flatten())


model.add(Dense(128,activation="relu"))
model.add(Dropout(0.2))
model.add(Dense(33,activation='softmax'))

# Configures the model for training
model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

epoch_num = 6
history= model.fit(X_train, y_train, epochs=epoch_num, batch_size=32,verbose=2,validation_data=(X_test, y_test))

test_loss, test_acc = model.evaluate(X_test, y_test)

print('Test accuracy: {:2.2f}%'.format(test_acc*100))

predictions = model.predict(X_test) # Make predictions towards the test set

np.argmax(predictions[10]), y_test[10] # If same, got it right

y_pred = np.argmax(predictions, axis=1)

"""**Confusion Matrix of Test Predictions**"""

cm =confusion_matrix(y_test, y_pred)

# pd.DataFrame(cm,
#              columns=['Predicted က','Predicted ခ','Predicted ','Predicted ','Predicted င','Predicted စ'],
#              index=['Actual က','Actual ခ','Actual ','Actual င','Actual ','Actual စ'])

plt.figure(figsize = (40,25))
sn.set(font_scale=2)
svm = sn.heatmap(cm, annot=True,fmt='g')
figure = svm.get_figure()    
figure.savefig('svm_conf.png', dpi=400)

"""# Visualize Training Result"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epoch_num)

plt.figure(figsize=(9, 9))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""# Model Evaluation"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy: %f' % accuracy)
# precision tp / (tp + fp)
precision = precision_score(y_test, y_pred,average = 'macro')
print('Precision: %f' % precision)
# recall: tp / (tp + fn)
recall = recall_score(y_test, y_pred,average = 'macro')
print('Recall: %f' % recall)
# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(y_test, y_pred,average = 'macro')
print('F1 score: %f' % f1)

"""# **Test Input Image**"""

img_input = cv2.imread("002_hh_2.png")
plt.imshow(img_input)
img_input= cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)
img_input = np.array(img_input,dtype="uint8")
img_input = np.expand_dims(img_input,axis=2)
img_input.shape

ret,imgt = cv2.threshold(img_input,130,255,cv2.THRESH_BINARY)

#img1= cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)
resize_img = cv2.resize(img_input,dsize=(50,50))
plt.imshow(resize_img)

#x_input = np.expand_dims(resize_img,axis=0)
x_input = np.expand_dims(resize_img,axis=2)
x_input = np.expand_dims(x_input,axis=0)
#x_input.shape
print(x_input.shape,X_test[50].shape)

y_input_pred = model.predict([x_input])
print(y_input_pred[0])

predict_result = np.argmax(y_input_pred, axis=1)
print(predict_result)

"""# Save Model"""

model.save("model6.h5")

character_dict = {0:'က', 1:'ခ', 2:'ဂ', 3:'ဃ', 4:'င', 5:'စ',
                  6:'ဆ', 7:'ဇ', 8:'ဈ', 9:'ည', 10:'ဋ',
                  11:'ဌ', 12:'ဍ', 13:'ဎ', 14:'ဏ', 15:'တ', 
                  16:'ထ', 17:'ဒ', 18:'ဓ', 19:'န', 20:'ပ',
                  21:'ဖ', 22:'ဗ', 23:'ဘ', 24:'မ', 25:'ယ', 
                  26:'ရ', 27:'လ', 28:'ဝ', 29:'သ', 30:'ဟ', 31:'ဠ', 32:'အ'}

import keras
import tensorflow
print(keras.__version__)
print(tensorflow.__version__)

